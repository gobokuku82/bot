# ì§€ì—­í™”í ê²€ìƒ‰ ì‹œìŠ¤í…œ ê¸°ìˆ  ë¬¸ì„œ

## ëª©ì°¨
1. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#1-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
2. [ì‘ë™ í”„ë¡œì„¸ìŠ¤](#2-ì‘ë™-í”„ë¡œì„¸ìŠ¤)
3. [ì£¼ìš” ê¸°ëŠ¥ ìƒì„¸](#3-ì£¼ìš”-ê¸°ëŠ¥-ìƒì„¸)
4. [ë°ì´í„° êµ¬ì¡°](#4-ë°ì´í„°-êµ¬ì¡°)
5. [ì„±ëŠ¥ ìµœì í™”](#5-ì„±ëŠ¥-ìµœì í™”)
6. [í™•ì¥ì„±](#6-í™•ì¥ì„±)
7. [í…ŒìŠ¤íŠ¸ ë°©ë²•](#7-í…ŒìŠ¤íŠ¸-ë°©ë²•)
8. [ìœ ì§€ë³´ìˆ˜](#8-ìœ ì§€ë³´ìˆ˜)

## 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1.1 ì „ì²´ êµ¬ì¡°
```
[ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ (Streamlit)]
        â†“
[ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (LangChain)]
        â†“
[ë„êµ¬ ëª¨ìŒ (Tools)]
        â†“
[ë°ì´í„°ë² ì´ìŠ¤/ì™¸ë¶€ API]
```

### 1.2 ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 1.2.1 í”„ë¡ íŠ¸ì—”ë“œ (app.py)
```python
import streamlit as st
from agents.agent_executor import agent_executor
from langchain_core.messages import AIMessage, HumanMessage
from dotenv import load_dotenv

load_dotenv()

st.set_page_config(page_title="ì§€ì—­ì‚¬ë‘ìƒí’ˆê¶Œ ì±—ë´‡", layout="wide")
st.title("ğŸ’¬ ì§€ì—­ì‚¬ë‘ìƒí’ˆê¶Œ ë©€í‹°í„´ ì±—ë´‡")

# ì„¸ì…˜ ìƒíƒœë¡œ ë©€í‹°í„´ ëŒ€í™” ìœ ì§€
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”? ì˜ˆ: 'ëª¨ë°”ì¼ ë˜ëŠ” ì¶©ì²­ë„ ì§€ì—­ìƒí’ˆê¶Œ ì•Œë ¤ì¤˜'")

if user_input:
    # ëŒ€í™” ê¸°ë¡ ì €ì¥
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    
    # Agent ì‹¤í–‰
    with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
        response = agent_executor.invoke({
            "input": user_input,
            "chat_history": st.session_state.chat_history
        })

    # ì‘ë‹µ ì €ì¥
    st.session_state.chat_history.append(AIMessage(content=response["output"]))
```

#### 1.2.2 ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ (agent_executor.py)
```python
import os
from typing import TypedDict, List
from langchain_core.tools import tool
from langchain_core.runnables import Runnable
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI

# LLM ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0,
    api_key=OPENAI_API_KEY
)

# ë„êµ¬ ì •ì˜
@tool
def filter_coupon_data(query: str) -> List[dict]:
    """ì§ˆë¬¸ì—ì„œ ì¡°ê±´ì„ ì¶”ì¶œí•˜ê³ , JSONL ë°ì´í„°ë¥¼ ì¡°ê±´ì— ë§ê²Œ í•„í„°ë§í•©ë‹ˆë‹¤."""
    cond = parse_conditions(query)
    data = load_jsonl("data/ì§€ì—­ì‚¬ë‘ìƒí’ˆê¶Œ_ê¸ì •_ë¶€ì •ì „ì²˜ë¦¬_cleaned.jsonl")
    results = filter_jsonl_by_condition(data, cond)
    return results[:30]

# ë„êµ¬ ëª©ë¡
tools = [
    filter_coupon_data,
    summarize_coupon_results,
    naver_local_search,
    naver_search  
]

# ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# Agent êµ¬ì„±
prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="ë‹¹ì‹ ì€ ì§€ì—­ì‚¬ë‘ìƒí’ˆê¶Œì— ëŒ€í•´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ë„êµ¬ë¥¼ ì‚¬ìš©í•´ ì‘ë‹µí•˜ëŠ” AIì…ë‹ˆë‹¤."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])

agent = create_openai_functions_agent(
    llm=llm,
    tools=tools,
    prompt=prompt
)

# AgentExecutor ìƒì„±
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True
)
```

## 2. ì‘ë™ í”„ë¡œì„¸ìŠ¤

### 2.1 ê¸°ë³¸ íë¦„ë„
```mermaid
graph TD
    A[ì‚¬ìš©ì ì…ë ¥] --> B[ì¿¼ë¦¬ ë¶„ë¥˜]
    B --> C{ë¶„ë¥˜ ê²°ê³¼}
    C -->|ë‚´ë¶€ ê²€ìƒ‰| D[ë°ì´í„° í•„í„°ë§]
    C -->|ì™¸ë¶€ ê²€ìƒ‰| E[ë„¤ì´ë²„ ê²€ìƒ‰]
    C -->|ê³„ì‚°ê¸°| F[ê³„ì‚° ì²˜ë¦¬]
    D --> G[ê²°ê³¼ ìš”ì•½]
    E --> G
    F --> G
    G --> H[ì‘ë‹µ ìƒì„±]
    H --> I[ì‚¬ìš©ìì—ê²Œ í‘œì‹œ]
```

### 2.2 ì¿¼ë¦¬ ë¶„ë¥˜ (query_classifier.py)
```python
from typing import TypedDict
from langchain_openai import ChatOpenAI

class QueryClassification(TypedDict):
    query_type: str  # "internal_search", "external_search", "calculator"
    confidence: float

def classify_query(query: str) -> QueryClassification:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤."""
    llm = ChatOpenAI(temperature=0)
    
    prompt = f"""
    ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì²˜ë¦¬ ë°©ì‹ì„ ê²°ì •í•´ì£¼ì„¸ìš”:
    ì§ˆë¬¸: {query}
    
    ê°€ëŠ¥í•œ ì²˜ë¦¬ ë°©ì‹:
    1. internal_search: ì§€ì—­í™”í ë°ì´í„°ë² ì´ìŠ¤ ë‚´ ê²€ìƒ‰
    2. external_search: ì™¸ë¶€ ì›¹ ê²€ìƒ‰ í•„ìš”
    3. calculator: ê³„ì‚°ê¸° ê¸°ëŠ¥ í•„ìš”
    
    JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
    {{
        "query_type": "ì²˜ë¦¬ë°©ì‹",
        "confidence": 0.0-1.0
    }}
    """
    
    response = llm.invoke(prompt)
    return eval(response.content)
```

## 3. ì£¼ìš” ê¸°ëŠ¥ ìƒì„¸

### 3.1 ë°ì´í„° í•„í„°ë§ (filter_tool.py)
```python
from typing import List, Dict
import json

def parse_conditions(query: str) -> Dict:
    """ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ ì¡°ê±´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    conditions = {
        "region": None,
        "support_type": None,
        "keywords": []
    }
    # ì¡°ê±´ íŒŒì‹± ë¡œì§
    return conditions

def load_jsonl(file_path: str) -> List[Dict]:
    """JSONL íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line))
    return data

def filter_jsonl_by_condition(data: List[Dict], conditions: Dict) -> List[Dict]:
    """ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤."""
    filtered_data = []
    for item in data:
        if matches_conditions(item, conditions):
            filtered_data.append(item)
    return filtered_data
```

### 3.2 LLM ë„êµ¬ (llm_tool.py)
```python
from typing import List, Dict
from langchain_openai import ChatOpenAI

def summarize_results(results: List[Dict]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
    llm = ChatOpenAI(temperature=0)
    
    prompt = f"""
    ë‹¤ìŒ ì§€ì—­í™”í ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:
    {results}
    
    ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½:
    1. ì´ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    2. ì£¼ìš” íŠ¹ì§•
    3. ì‚¬ìš© ê°€ëŠ¥ ì§€ì—­
    4. ì§€ì› ë°©ì‹
    """
    
    response = llm.invoke(prompt)
    return response.content
```

## 4. ë°ì´í„° êµ¬ì¡°

### 4.1 JSONL ë°ì´í„° í˜•ì‹
```json
{
  "content": "ì œì£¼ ì œì£¼ì‹œì—ì„œëŠ” \"[ì œì£¼íŠ¹ë³„ìì¹˜ë„]íƒë‚˜ëŠ”ì „\"ì´ ì œê³µë˜ë©°, ì§€ë¥˜í˜•, ëª¨ë°”ì¼, ì¹´ë“œí˜•ì€ ì§€ì›ë˜ë©°.",
  "metadata": {
    "ì§€ì—­1": "ì œì£¼",
    "ì§€ì—­2": "ì œì£¼ì‹œ", 
    "ì´ë¦„": "[ì œì£¼íŠ¹ë³„ìì¹˜ë„]íƒë‚˜ëŠ”ì „",
    "ì§€ì›ë°©ì‹": ["ì§€ë¥˜í˜•", "ëª¨ë°”ì¼", "ì¹´ë“œí˜•"],
    "ë¹„ì§€ì›ë°©ì‹": [],
    "ë§í¬": "http://tamna.jeju.go.kr/mainView.do"
  }
}
```

## 5. ì„±ëŠ¥ ìµœì í™”

### 5.1 ìºì‹± ì „ëµ
```python
import streamlit as st
from functools import lru_cache

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë”© ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    return load_jsonl("data/ì§€ì—­ì‚¬ë‘ìƒí’ˆê¶Œ_ê¸ì •_ë¶€ì •ì „ì²˜ë¦¬_cleaned.jsonl")

@lru_cache(maxsize=100)
def search_cache(query: str, k: int = 5):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìºì‹±í•©ë‹ˆë‹¤."""
    return vector_db.search(query, k=k)
```

## 6. í™•ì¥ì„±

### 6.1 ìƒˆë¡œìš´ ë„êµ¬ ì¶”ê°€ ì˜ˆì‹œ
```python
@tool
def new_custom_tool(query: str) -> str:
    """ìƒˆë¡œìš´ ì»¤ìŠ¤í…€ ë„êµ¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
    # ë„êµ¬ ë¡œì§ êµ¬í˜„
    return "ê²°ê³¼"
```

## 7. í…ŒìŠ¤íŠ¸ ë°©ë²•

### 7.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
```python
import unittest
from tools.filter_tool import parse_conditions, filter_jsonl_by_condition

class TestFilterTool(unittest.TestCase):
    def test_parse_conditions(self):
        query = "ê²½ê¸°ë„ ëª¨ë°”ì¼ ì§€ì—­í™”í"
        conditions = parse_conditions(query)
        self.assertEqual(conditions["region"], "ê²½ê¸°ë„")
        self.assertEqual(conditions["support_type"], "ëª¨ë°”ì¼")

    def test_filter_jsonl(self):
        data = [{"metadata": {"ì§€ì—­1": "ê²½ê¸°ë„", "ì§€ì›ë°©ì‹": ["ëª¨ë°”ì¼"]}}]
        conditions = {"region": "ê²½ê¸°ë„", "support_type": "ëª¨ë°”ì¼"}
        results = filter_jsonl_by_condition(data, conditions)
        self.assertEqual(len(results), 1)
```

## 8. ìœ ì§€ë³´ìˆ˜

### 8.1 ë¡œê¹… ì„¤ì •
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def log_error(error: Exception):
    """ì—ëŸ¬ ë¡œê¹…"""
    logger.error(f"Error occurred: {str(error)}", exc_info=True)
```

### 8.2 ëª¨ë‹ˆí„°ë§
```python
import time
from functools import wraps

def monitor_performance(func):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ì„ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        logger.info(f"{func.__name__} ì‹¤í–‰ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
        return result
    return wrapper
```

## ê²°ë¡ 

ì´ ì‹œìŠ¤í…œì€ ì§€ì—­í™”í ì •ë³´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  ì œê³µí•˜ëŠ” ì¢…í•©ì ì¸ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¸í„°í˜ì´ìŠ¤ì™€ ê°•ë ¥í•œ ê²€ìƒ‰ ê¸°ëŠ¥ì„ í†µí•´ ì§€ì—­í™”í ì •ë³´ì— ëŒ€í•œ ì ‘ê·¼ì„±ì„ ë†’ì´ê³  ìˆìŠµë‹ˆë‹¤. ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ ê°œì„ ì„ í†µí•´ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤. 